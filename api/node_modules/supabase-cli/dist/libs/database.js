"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.resetDatabase = exports.execResourceDatabase = exports.clearDatabase = exports.restoreDatabase = exports.dumpDatabase = exports.dumpTable = exports.migrateDatabaseGotrue = exports.migrateDatabaseUser = exports.migrateDatabase = exports.getClient = exports.execDatabaseExsFiles = exports.execDatabaseFiles = exports.execDatabase = void 0;
const fs_1 = require("fs");
const path_1 = __importDefault(require("path"));
const pg_1 = require("pg");
const postgres_migrations_1 = require("postgres-migrations");
const stdlibs_1 = require("./stdlibs");
const supabase_1 = require("./supabase");
const execDatabase = async ({ host, dbname = "postgres", port, password, query, values, }) => {
    const client = await (0, exports.getClient)({ host, port, dbname, password });
    if (!client)
        return false;
    try {
        return ((await client.query(query, values).catch((e) => {
            console.error(e);
            return undefined;
        })) !== undefined);
    }
    finally {
        await client.end();
    }
};
exports.execDatabase = execDatabase;
const execDatabaseFiles = async ({ host, port, password, dir, }) => {
    const files = await (await fs_1.promises.readdir(dir).catch(() => [])).sort();
    for (const file of files) {
        const value = await fs_1.promises
            .readFile(`${dir}/${file}`, "utf8")
            .catch(() => undefined);
        if (value) {
            console.log("  " + file);
            await (0, exports.execDatabase)({ host, port, password, query: value });
        }
    }
};
exports.execDatabaseFiles = execDatabaseFiles;
const execDatabaseExsFiles = async ({ host, port, password, dir, }) => {
    const files = await (await fs_1.promises.readdir(dir).catch(() => [])).sort();
    await (0, exports.execResourceDatabase)({
        host,
        port,
        password,
        fileName: "create_realtime_migration.sql",
    });
    for (const file of files) {
        console.log("  " + file);
        const value = await fs_1.promises
            .readFile(`${dir}/${file}`, "utf8")
            .catch(() => undefined);
        if (value) {
            const sqls = [...value.matchAll(/execute.*?"([\s\S]*?[^\\])"/gm)].map((v) => v[1].replace(/^[ ]*/gm, ""));
            for (const query of sqls)
                await (0, exports.execDatabase)({ query });
            const id = file.match(/([^/\\]*?)_.*$/)?.[1];
            id &&
                (await (0, exports.execDatabase)({
                    host,
                    port,
                    password,
                    query: `insert into realtime.schema_migrations values($1,now() at time zone 'utc')`,
                    values: [Number(id)],
                }));
        }
    }
};
exports.execDatabaseExsFiles = execDatabaseExsFiles;
const getClient = async (params) => {
    const { host = "localhost", port: portSrc, dbname = "postgres", password: passwordSrc, } = params || {};
    const config = await (0, supabase_1.getSupabaseEnv)();
    const password = passwordSrc || config?.POSTGRES_PASSWORD;
    const port = portSrc || Number(config?.POSTGRES_PORT);
    const dbConfig = {
        host: host ? host : "localhost",
        port,
        password,
        user: "postgres",
        database: dbname,
        connectionTimeoutMillis: 10_000,
    };
    const client = new pg_1.Client(dbConfig);
    let isError = false;
    await client.connect((err) => {
        if (err) {
            console.error(err);
            isError = true;
        }
    });
    return isError ? undefined : client;
};
exports.getClient = getClient;
const migrateDatabase = async ({ host, port, dbname, password, dir, schema, }) => {
    const client = await (0, exports.getClient)({ host, port, dbname, password });
    if (!client)
        return false;
    try {
        await client.query(`create schema IF NOT EXISTS "${schema}"`);
        await client.query(`SET search_path to "${schema}"`);
        await client.query(`CREATE TABLE IF NOT EXISTS "${schema}".migrations (
  id integer PRIMARY KEY,
  name varchar(100) UNIQUE NOT NULL,
  hash varchar(40) NOT NULL, -- sha1 hex encoded hash of the file name and contents, to ensure it hasn't been altered since applying the migration
  executed_at timestamp DEFAULT current_timestamp
);`);
        await (0, postgres_migrations_1.migrate)({ client }, dir);
    }
    finally {
        await client.end();
    }
};
exports.migrateDatabase = migrateDatabase;
const migrateDatabaseUser = async ({ host, port, dbname, password, dir, }) => {
    const files = await (await fs_1.promises.readdir(dir).catch(() => [])).sort();
    const client = await (0, exports.getClient)({ host, port, dbname, password });
    if (!client)
        return false;
    try {
        const schema = "cli";
        await client.query(`create schema IF NOT EXISTS "${schema}"`);
        await client.query(`CREATE TABLE IF NOT EXISTS "${schema}".migrations (
  name varchar(256) PRIMARY KEY,
  executed_at timestamp DEFAULT current_timestamp
);`);
        for (const file of files) {
            const value = await fs_1.promises
                .readFile(`${dir}/${file}`, "utf8")
                .catch(() => undefined);
            if (value) {
                const r = await client.query(`select true from "${schema}".migrations where name=$1`, [file]);
                if (r.rowCount === 0) {
                    console.log("  " + file);
                    await client.query("begin;");
                    if (!(await client.query(value))) {
                        await client.query("rollback;");
                        break;
                    }
                    await client.query(`insert into "${schema}".migrations values($1,default)`, [file]);
                    await client.query("commit;");
                }
            }
        }
        await client.query("select graphql.rebuild_schema();");
    }
    finally {
        await client.end();
    }
};
exports.migrateDatabaseUser = migrateDatabaseUser;
const migrateDatabaseGotrue = async ({ host, port, dbname, password, dir, }) => {
    const files = await (await fs_1.promises.readdir(dir).catch(() => [])).sort();
    const client = await (0, exports.getClient)({ host, port, dbname, password });
    if (!client)
        return false;
    try {
        await client.query(`SET search_path to auth`);
        for (const file of files) {
            const value = await fs_1.promises
                .readFile(`${dir}/${file}`, "utf8")
                .catch(() => undefined);
            if (value) {
                const id = file?.match(/^(.*?)_/)?.[1];
                if (!id)
                    continue;
                const r = await client.query(`select true from auth.schema_migrations where version=$1`, [id]);
                if (r.rowCount === 0) {
                    console.log("  " + file);
                    await client.query("begin;");
                    if (!(await client.query(value))) {
                        await client.query("rollback;");
                        break;
                    }
                    await client.query(`insert into auth.schema_migrations values($1)`, [
                        id,
                    ]);
                    await client.query("commit;");
                }
            }
        }
    }
    finally {
        await client.end();
    }
};
exports.migrateDatabaseGotrue = migrateDatabaseGotrue;
const dumpTable = async ({ host, port, password, tableName, fileName, }) => {
    const project = process.env.npm_package_name || "supabase";
    const stream = (0, fs_1.openSync)(fileName, "w");
    if (!stream)
        return false;
    const code = await (0, stdlibs_1.spawn)(`docker compose -p ${project} -f supabase/docker/docker-compose.yml exec db pg_dump -c -s -t "${tableName}" --if-exists postgres://postgres${password ? ":" + password : ""}@${host || "localhost"}:${port || 5432}/postgres`, { stdio: ["inherit", stream, "inherit"] });
    (0, fs_1.closeSync)(stream);
    return code === 0;
};
exports.dumpTable = dumpTable;
const dumpDatabase = async ({ host, port, password, fileName, }) => {
    const project = process.env.npm_package_name || "supabase";
    const stream = (0, fs_1.openSync)(fileName, "w");
    if (!stream)
        return false;
    const code = await (0, stdlibs_1.spawn)(`docker compose -p ${project} -f supabase/docker/docker-compose.yml exec db pg_dump postgres://postgres${password ? ":" + password : ""}@${host || "localhost"}:${port || 5432}/postgres`, { stdio: ["inherit", stream, "inherit"] });
    (0, fs_1.closeSync)(stream);
    return code === 0;
};
exports.dumpDatabase = dumpDatabase;
const restoreDatabase = async ({ host, port, password, fileName, }) => {
    const project = process.env.npm_package_name || "supabase";
    const stream = (0, fs_1.openSync)(fileName, "r");
    if (!stream)
        return false;
    const code = await (0, stdlibs_1.spawn)(`docker compose -p ${project} -f supabase/docker/docker-compose.yml exec db psql postgres://postgres${password ? ":" + password : ""}@${host || "localhost"}:${port || 5432}/postgres`, { stdio: [stream, "inherit", "inherit"] });
    (0, fs_1.closeSync)(stream);
    return code === 0;
};
exports.restoreDatabase = restoreDatabase;
const clearDatabase = async (params) => {
    const { host, port, password } = params || {};
    await (0, exports.execDatabase)({
        host,
        port,
        password,
        dbname: "template1",
        query: `GRANT pg_signal_backend TO postgres;`,
    });
    await (0, exports.execDatabase)({
        host,
        port,
        password,
        dbname: "template1",
        query: `DROP DATABASE IF EXISTS old;`,
    });
    await (0, exports.execDatabase)({
        host,
        port,
        password,
        dbname: "template1",
        query: `
do $$ 
  begin 
    if (select true from pg_database where datname='postgres') then
      EXECUTE 'SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = ''postgres''';
      ALTER DATABASE postgres RENAME TO old;
    end if;
  end; 
$$;
`,
    });
    await (0, exports.execDatabase)({
        dbname: "template1",
        host,
        port,
        password,
        query: "CREATE DATABASE postgres TEMPLATE template0;",
    });
    await (0, exports.execDatabase)({
        dbname: "template1",
        host,
        port,
        password,
        query: "DROP DATABASE IF EXISTS old;",
    });
};
exports.clearDatabase = clearDatabase;
const execResourceDatabase = async ({ host, port, password, fileName, }) => {
    const query = await fs_1.promises
        .readFile(path_1.default.resolve(__dirname, "../..", "resources", fileName), "utf8")
        .catch((e) => console.error(e));
    if (!query)
        return false;
    return await (0, exports.execDatabase)({
        host,
        port,
        password,
        query,
    });
};
exports.execResourceDatabase = execResourceDatabase;
const resetDatabase = async (params) => {
    const { host, port, password } = params || {};
    console.log("Create database");
    await (0, exports.clearDatabase)({ host, port, password });
    console.log("Clear users");
    await (0, exports.execResourceDatabase)({
        host,
        port,
        password,
        fileName: "clear_users.sql",
    });
    console.log("Initialization of supabase");
    await (0, exports.execDatabaseFiles)({
        host,
        port,
        password,
        dir: "supabase/docker/volumes/db/init",
    });
    await (0, exports.execResourceDatabase)({
        host,
        port,
        password,
        fileName: "restore_users.sql",
    });
    console.log("Migration of storage-api");
    await (0, exports.migrateDatabase)({
        host,
        port,
        password,
        dir: "supabase/system-migrations/storage-api",
        schema: "storage",
    });
    console.log("Migration of gotrue-api");
    await (0, exports.migrateDatabaseGotrue)({
        host,
        port,
        password,
        dir: "supabase/system-migrations/gotrue",
    });
    if (!host) {
        console.log("Migration of realtime-api");
        await (0, exports.execDatabaseExsFiles)({
            host,
            port,
            password,
            dir: "supabase/system-migrations/realtime",
        });
    }
    console.log("Migration of user files");
    await (0, exports.migrateDatabaseUser)({
        host,
        port,
        password,
        dir: "supabase/migrations",
    });
};
exports.resetDatabase = resetDatabase;
